import time
from collections import deque

import cv2
import numpy as np
from gpiozero import Servo

# ----------------- Hardware -----------------
SERVO_PIN = 17
servo = Servo(SERVO_PIN)

def open_latch():
    # Adjust these positions for your latch geometry
    servo.max()
    time.sleep(0.5)
    servo.mid()

# ----------------- Vision tuning knobs -----------------
FRAME_W, FRAME_H = 640, 480

# Threshold for "bright spot"
THRESH_VAL = 240          # 0-255; lower if dot isn't picked up
MIN_AREA = 30             # ignore tiny blobs (noise)
ERODE_ITERS = 1
DILATE_ITERS = 2

# Motion / gesture
BUFFER_LEN = 20           # points tracked (~1 sec at ~20fps)
STILL_EPS = 7             # px: movement smaller than this counts as "still"
STILL_FRAMES_TO_END = 6   # how many still frames = end of gesture
DX_THRESHOLD = 120        # pixels moved to count gesture
DY_THRESHOLD = 120
COOLDOWN_SEC = 2.0        # ignore triggers right after opening

# ----------------- Gesture classification -----------------
def classify_gesture(points):
    """
    points: list of (x,y)
    returns one of RIGHT/LEFT/UP/DOWN or None
    """
    if len(points) < 8:
        return None

    x0, y0 = points[0]
    x1, y1 = points[-1]
    dx, dy = x1 - x0, y1 - y0

    # Require meaningful movement
    if abs(dx) < DX_THRESHOLD and abs(dy) < DY_THRESHOLD:
        return None

    # Dominant axis decides gesture
    if abs(dx) > abs(dy):
        return "RIGHT" if dx > 0 else "LEFT"
    else:
        # y increases downward in image coordinates
        return "DOWN" if dy > 0 else "UP"

# ----------------- Main loop -----------------
def main():
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_W)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_H)

    pts = deque(maxlen=BUFFER_LEN)
    last_pt = None
    still_frames = 0
    last_trigger_time = 0.0

    while True:
        ok, frame = cap.read()
        if not ok:
            print("Camera read failed.")
            break

        # Preprocess for bright-dot detection
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (7, 7), 0)

        _, th = cv2.threshold(gray, THRESH_VAL, 255, cv2.THRESH_BINARY)
        th = cv2.erode(th, None, iterations=ERODE_ITERS)
        th = cv2.dilate(th, None, iterations=DILATE_ITERS)

        contours, _ = cv2.findContours(th, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        pt = None
        if contours:
            c = max(contours, key=cv2.contourArea)
            area = cv2.contourArea(c)
            if area >= MIN_AREA:
                M = cv2.moments(c)
                if M["m00"] != 0:
                    cx = int(M["m10"] / M["m00"])
                    cy = int(M["m01"] / M["m00"])
                    pt = (cx, cy)

        # Update tracking state
        if pt is not None:
            pts.append(pt)
            cv2.circle(frame, pt, 6, (0, 255, 0), -1)

            if last_pt is not None:
                dist = np.hypot(pt[0] - last_pt[0], pt[1] - last_pt[1])
                if dist < STILL_EPS:
                    still_frames += 1
                else:
                    still_frames = 0
            last_pt = pt
        else:
            # If we lose the dot, count as still
            still_frames += 1

        # End-of-gesture detection
        if still_frames >= STILL_FRAMES_TO_END and len(pts) > 0:
            now = time.time()
            gesture = classify_gesture(list(pts))
            print("Gesture:", gesture)

            if gesture == "RIGHT":  # choose your "spell"
                if (now - last_trigger_time) > COOLDOWN_SEC:
                    print("Unlock!")
                    open_latch()
                    last_trigger_time = now

            pts.clear()
            still_frames = 0
            last_pt = None

        # Draw trail
        for i in range(1, len(pts)):
            cv2.line(frame, pts[i - 1], pts[i], (255, 255, 255), 2)

        cv2.imshow("frame", frame)
        cv2.imshow("threshold", th)

        key = cv2.waitKey(1) & 0xFF
        if key == 27:  # ESC
            break
        elif key == ord(']'):
            # raise threshold (less sensitive)
            global THRESH_VAL
            THRESH_VAL = min(255, THRESH_VAL + 5)
            print("THRESH_VAL:", THRESH_VAL)
        elif key == ord('['):
            # lower threshold (more sensitive)
            THRESH_VAL = max(0, THRESH_VAL - 5)
            print("THRESH_VAL:", THRESH_VAL)

    cap.release()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
